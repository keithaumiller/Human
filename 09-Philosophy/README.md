This is not a philosophical effort.  This is a scientific one and requires clear metrics, measures, processes, etc to be defined.

I am aware of how absurd it is to attempt to set the goals of humanity.  It is sort of like defining the meaning of life and there will be a lot of discusion and debate.  At present, the goals of humanity are determined by whomever has the most resources and directs them towards those goals.  There are attempts to pool resources and build for the common good, but governments are institutions and institutions are fun by individuals, which leads to corruption over time.  With the right framework, perhaps we can reduce corruption and give AIs a chance to improve our goals overall.  

The only common goal individuals seem to consistently abide by is survival.  Quality of life goals are secondary and only slightly less important.  Individuals who don't prioritize survival are often prioritizing the survival of a larger institution which they love.

Only by creating a model for forecasting outcomes and simulating scenarios can we get closer to our common goals.

I expect that this framework will be adapted to weight different aspects of humanity differently.  Each ethnic group or special interrest group will have their own priorities and implement their own governance AI at some point.  I intend to keep this one as neutral and fair to all interrests as possible and attempt to keep the focus on all of humanities survival, expansion, and happiness.

General strategy
1. Define clear goals
2. Define clear KPIs at the top and work backwards
3. Establish what algorithms, sensors, metrics, etc help to improve the overall forecast and which don't
4. Leverage new research as it emerges
5. Constantly be updating and linking to new data sources for longitudinal data that can improve the forecast of these indexes.
